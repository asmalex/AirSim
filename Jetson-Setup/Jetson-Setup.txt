=========================
NVIDIA Jetson Nano Setup
=========================

1) Write Image to the microSD Card
-----------------------------------
To prepare your microSD card, you’ll need a computer with Internet connection and the ability to read and write SD cards, either via a built-in SD card slot or adapter.


2) Setup
---------
There are two ways to interact with the developer kit: 
i) with display, keyboard and mouse attached, or 
ii) in “headless mode” via connection from another computer.

You can conduct the initial setup either way.


3) First Boot
--------------
A green LED next to the Micro-USB connector will light as soon as the developer kit powers on. When you boot the first time, the developer kit will take you through some initial setup, including:

Review and accept NVIDIA Jetson software EULA
Select system language, keyboard layout, and time zone
Create username, password, and computer name
Select APP partition size—it is recommended to use the max size suggested


4) Setup NVIDIA's Jetson Inference Libraries
---------------------------------------------
There are three options to setup NVIDIA's Jetson inference libraries:

i) Building project from source (no containers)
************************************************
URL: https://github.com/dusty-nv/jetson-inference/blob/master/docs/building-repo-2.md

If you aren't using the Docker container, here's a condensed form of the commands to build/install the project directly on your Jetson:
$ sudo apt-get update
$ sudo apt-get install git cmake libpython3-dev python3-numpy
$ git clone --recursive https://github.com/dusty-nv/jetson-inference
$ cd jetson-inference
$ mkdir build
$ cd build
$ cmake ../
$ make -j$(nproc)
$ sudo make install
$ sudo ldconfig

ii) Running the pre-built Docker container
*******************************************
URL: https://github.com/dusty-nv/jetson-inference/blob/master/docs/aux-docker.md

Due to various mounts and devices needed to run the container, it's recommended to use the docker/run.sh script to run the container:
$ git clone --recursive https://github.com/dusty-nv/jetson-inference
$ cd jetson-inference
$ docker/run.sh

iii) Building the Docker container (recommended)
*************************************************
IMPORTANT NOTE: you should first set your default docker-runtime to nvidia

To enable access to the CUDA compiler (nvcc) during docker build operations, add "default-runtime": "nvidia" to your /etc/docker/daemon.json configuration file before attempting to build the containers:

{
    "runtimes": {
        "nvidia": {
            "path": "nvidia-container-runtime",
            "runtimeArgs": []
        }
    },

    "default-runtime": "nvidia"
}
You will then want to restart the Docker service or reboot your system before proceeding.
######################################################################################################
If you wish to re-build the container or build your own, you can use the docker/build.sh script which builds the project's Dockerfile:

I have modified the original Dockerfile to include the installation of TensorFlow. Replace the original Dockerfile with the modified Dockerfile at:
~/jetson-inference/Dockerfile

###########################################################################################################
IMPORTANT NOTE: do not "sudo apt upgrade" the system as doing so will break the container building process
###########################################################################################################

$ git clone --recursive https://github.com/dusty-nv/jetson-inference
$ cd jetson-inference
$ docker/build.sh
$ sudo docker images (this command should list jetson-inference repository with tag r32.6.1)
$ docker/run.sh

######################################################################################################